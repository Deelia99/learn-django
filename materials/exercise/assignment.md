<a href="https://github.com/drshahizan/learn-django/stargazers"><img src="https://img.shields.io/github/stars/drshahizan/learn-django" alt="Stars Badge"/></a>
<a href="https://github.com/drshahizan/learn-django/network/members"><img src="https://img.shields.io/github/forks/drshahizan/learn-django" alt="Forks Badge"/></a>
<a href="https://github.com/drshahizan/learn-django/pulls"><img src="https://img.shields.io/github/issues-pr/drshahizan/learn-django" alt="Pull Requests Badge"/></a>
<a href="https://github.com/drshahizan/learn-django/issues"><img src="https://img.shields.io/github/issues/drshahizan/learn-django" alt="Issues Badge"/></a>
<a href="https://github.com/drshahizan/learn-django/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/drshahizan/learn-django?color=2b9348"></a>
![](https://visitor-badge.glitch.me/badge?page_id=drshahizan/learn-django)

Don't forget to hit the :star: if you like this repo.

# Assignment Details

The goal of this assignment is to create a web application using Django that implements CRUD (Create, Read, Update, Delete) functionality. 

**Project Requirements:**

1. Create a Django project from scratch or use an existing one.

2. Create at least one Django app to handle the CRUD functionality.

3. Create a model for your data. This model should include fields for the data you want to store.

4. Create a view for each of the CRUD operations.

5. Use templates to render the views and display the data.

6. Create forms to handle the input of data.

7. Implement validation to ensure that the data entered is correct.

8. Implement user authentication and authorization to ensure that only authorized users can perform CRUD operations.

**Project Steps:**

1. Create a new Django project using the `django-admin startproject` command.

2. Create a new Django app using the `python manage.py startapp` command.

3. Define your model in the app's `models.py` file. You can use Django's built-in fields or create custom fields. 

4. Create a view to handle the creation of new data. In this view, create a form using Django's built-in forms or create custom forms.

5. Create a view to handle the retrieval of data. This view should display a list of all the data entries in the database.

6. Create a view to handle the updating of data. In this view, create a form to allow users to update an existing data entry.

7. Create a view to handle the deletion of data. This view should prompt the user to confirm the deletion before deleting the data.

8. Create templates for each view using HTML, CSS, and Django's templating language.

9. Implement validation for your forms to ensure that the data entered is correct. You can use Django's built-in validators or create custom validators.

10. Implement user authentication and authorization using Django's built-in authentication system or a third-party library like Django-Allauth.

**Submission Requirements:**

1. Submit the source code of your project along with any necessary configuration files.

2. Include a README file that provides instructions on how to run the project and any dependencies.

3. Provide screenshots or a video demo of your project in action, showcasing each of the CRUD operations.

4. Clearly document any assumptions or limitations in your implementation.

**Conclusion:**

By completing this assignment, you will have gained a practical understanding of how to create a web application using Django that implements CRUD functionality. This will help you in developing more complex web applications in the future. Good luck!
#### 5. Conclusion

- Summarize the main points of the assignment and restate the importance of web scraping multimedia content for data analysis.
- Offer suggestions for future research or analysis using the data set obtained from Flickr.

### Part 2: Web scraping text content
You need to find a website relevant to data publication content, such as the [Google Scholar](google-scholar.md) website. Google Scholar is a popular search engine for academic publications, making it an excellent source for web scraping data related to the Faculty of Computing at the University of Technology Malaysia. Here is a suggested outline for the assignment:

#### 1. Introduction
- Briefly introduce the topic of web scraping publication content and the importance of this type of data for research and analysis.

#### 2. Web Scraping Google Scholar
- Explain why Google Scholar is a good source for publication content and provide a brief overview of the site.
- Detail the web scraping process, including the tools and libraries used and any challenges that were encountered.
- Discuss the data set obtained, including metadata such as data size, file type, and other relevant information.

#### 3. Choosing a Library for Web Scraping
- Compare and contrast the available libraries for web scraping publication content, including Beautiful Soup, Scrapy, and Selenium.
- Explain the criteria used to choose the appropriate library for this project.
- Justify the final choice and explain the advantages of the chosen library.

#### 4. Storing Data in MongoDB
- Discuss the benefits of using MongoDB for storing publication content data.
- Explain the best way to store the data in MongoDB, including the data structure and organization.
- Provide examples of how the data can be queried and analyzed using MongoDB.

#### 5. Conclusion
- Summarize the main points of the assignment and restate the importance of web scraping publication content for data analysis.
- Offer suggestions for future research or analysis using the data set obtained from Google Scholar.

Overall, this write-up should demonstrate a thorough understanding of the process of web scraping publication content, as well as the tools and libraries used for this task. It should also provide a clear and detailed explanation of how the data is stored and organized in MongoDB for efficient querying and analysis.

### Others
- Collaborate effectively with your group members to complete the task.
- Ensure to send the report in **mark down** format and **source code**.
- Please submit the assignments in the submission [**Part 1**](https://github.com/drshahizan/learn-django/tree/main/assignment/data-scraping/submission/part1) and [**Part 2**](https://github.com/drshahizan/special-topic-data-engineering/tree/main/assignment/data-scraping/submission/part2) folder. It would be best if you create a folder using your group name.

## Contribution üõ†Ô∏è
Please create an [Issue](https://github.com/drshahizan/learn-django/issues) for any improvements, suggestions or errors in the content.

You can also contact me using [Linkedin](https://www.linkedin.com/in/drshahizan/) for any other queries or feedback.

![](https://visitor-badge.glitch.me/badge?page_id=drshahizan)



